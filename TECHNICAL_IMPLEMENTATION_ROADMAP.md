# í€€íŠ¸ í”¼ë“œë°± í•´ê²° - ê¸°ìˆ  êµ¬í˜„ ë¡œë“œë§µ

## ğŸ”§ Phase 1: ê³¼ì í•© ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜ (ìš°ì„ ìˆœìœ„ 1ìˆœìœ„)

### Task 1.1: Walk-Forward Analysis ìë™í™”
**ë‹´ë‹¹**: ë°±í…ŒìŠ¤íŒ… ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ê¸°ê°„**: 3ì¼  
**ê²€ì¦**: OOS ì„±ê³¼ ë¦¬í¬íŠ¸ ìë™ ìƒì„±

```python
# src/backtester/walk_forward_auto.py (ì‹ ê·œ)

class AutomatedWalkForwardAnalysis:
    """
    ìë™í™”ëœ Walk-forward ë¶„ì„
    """
    def __init__(self, 
                 data: pd.DataFrame,
                 train_period: int = 252 * 2,  # 2ë…„
                 test_period: int = 252,  # 1ë…„
                 step: int = 63):  # 3ê°œì›” ë¡¤ë§
        self.data = data
        self.train_period = train_period
        self.test_period = test_period
        self.step = step
    
    def run(self) -> WalkForwardReport:
        """
        Walk-forward ìë™ ì‹¤í–‰
        
        Returns:
            {
                'in_sample': [ì„±ê³¼1, ì„±ê³¼2, ...],
                'out_of_sample': [ì„±ê³¼1, ì„±ê³¼2, ...],
                'overfitting_ratio': OOS/IS,  # < 0.7ì´ë©´ ì‹¬ê°í•œ ê³¼ì í•©
                'parameter_stability': parameter_heatmap,
            }
        """
        results = []
        
        for i in range(0, len(self.data) - self.train_period - self.test_period, self.step):
            train_data = self.data.iloc[i:i+self.train_period]
            test_data = self.data.iloc[i+self.train_period:i+self.train_period+self.test_period]
            
            # 1. Training êµ¬ê°„ì—ì„œ íŒŒë¼ë¯¸í„° ìµœì í™”
            optimal_params = self._optimize_params(train_data)
            
            # 2. Test êµ¬ê°„ì—ì„œ OOS ì„±ê³¼ ì¸¡ì •
            is_result = self._backtest(train_data, optimal_params)
            oos_result = self._backtest(test_data, optimal_params)
            
            results.append({
                'period': f"{train_data.index[0]:%Y-%m-%d} ~ {test_data.index[-1]:%Y-%m-%d}",
                'in_sample': is_result,
                'out_of_sample': oos_result,
                'params': optimal_params,
            })
        
        return self._aggregate_results(results)

# ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
if __name__ == "__main__":
    # 8ë…„ ë°ì´í„° ë¡œë“œ
    data = pd.read_parquet("data/processed/KRW-BTC.parquet")
    
    # Walk-forward ë¶„ì„ ì‹¤í–‰
    wf = AutomatedWalkForwardAnalysis(data)
    report = wf.run()
    
    # ê²°ê³¼ ë¶„ì„
    print(f"In-Sample Avg Return: {report['is_avg']:.2%}")
    print(f"Out-of-Sample Avg Return: {report['oos_avg']:.2%}")
    print(f"Overfitting Ratio: {report['oos_avg']/report['is_avg']:.2%}")
    
    # ê¸°ëŒ€ê°’: 0.5-0.7 (30-50% ì•…í™”ëŠ” ì •ìƒ)
    # ë¬¸ì œ: < 0.2ë¼ë©´ ì‹¬ê°í•œ ê³¼ì í•©
    
    if report['oos_avg']/report['is_avg'] < 0.2:
        raise OverfittingError("ì‹¬ê°í•œ ê³¼ì í•© ê°ì§€!")
```

**ê²€ì¦ ê¸°ì¤€**:
- âœ… OOS/IS ë¹„ìœ¨ > 0.3 (ê³¼ì í•© ì•„ë‹˜)
- âœ… OOS ìˆ˜ìµë¥ ì´ ì–‘ìˆ˜ (ì†ì‹¤ì´ ì•„ë‹˜)
- âœ… OOS Sharpe > 0 (í†µê³„ì  ì˜ë¯¸ ìˆìŒ)

**ê²°ê³¼ í™œìš©**:
- READMEì— "OOS ì„±ê³¼: X%" ê³µê°œ
- 38,331% â†’ í˜„ì‹¤ ìˆ˜ì¹˜ë¡œ ìˆ˜ì •

---

### Task 1.2: Parameter Robustness ë¶„ì„
**ë‹´ë‹¹**: ë°±í…ŒìŠ¤íŒ… ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ê¸°ê°„**: 2ì¼

```python
# src/backtester/robustness_analysis.py (ì‹ ê·œ)

class RobustnessAnalyzer:
    """
    íŒŒë¼ë¯¸í„° ê°ë„ ë¶„ì„
    """
    def analyze(self, 
                optimal_params: dict,
                parameter_ranges: dict) -> HeatmapReport:
        """
        ìµœì  íŒŒë¼ë¯¸í„° ì£¼ë³€ì—ì„œ ì„±ê³¼ ë³€í™” ë¶„ì„
        
        ì˜ˆ: sma_period = 4 (ìµœì )
            â†’ [1, 2, 3, 4, 5, 6, 7] ë²”ìœ„ì—ì„œ ê°ê° ë°±í…ŒìŠ¤íŠ¸
            â†’ ê·¸ë˜í”„: íŒŒë¼ë¯¸í„° vs ì„±ê³¼
        """
        
# ì‚¬ìš© ì˜ˆ:
analyzer = RobustnessAnalyzer()

# sma_period = 4 (ìµœì ê°’), Â±50% ë³€í™” í…ŒìŠ¤íŠ¸
report = analyzer.analyze(
    optimal_params={'sma_period': 4, 'noise_period': 8},
    parameter_ranges={
        'sma_period': [2, 3, 4, 5, 6],  # Â±50%
        'noise_period': [4, 6, 8, 10, 12],  # Â±50%
    }
)

# ê²°ê³¼:
# - íŒŒë¼ë¯¸í„° ë³€í™” ì‹œ ì„±ê³¼ ê³¡ì„ ì´ ë¶€ë“œëŸ¬ìš´ê°€?
# - ìµœì ê°’ì—ì„œ ë²—ì–´ë‚˜ë©´ ê¸‰ê²©íˆ ë‚˜ë¹ ì§€ëŠ”ê°€?
# - í‰í‰í•œ ê³¡ì„  = ê³¼ì í•© ìœ„í—˜ ì‹ í˜¸
```

**ê²€ì¦ ê¸°ì¤€**:
- âœ… íŒŒë¼ë¯¸í„° Â±20% ë³€í™” â†’ ì„±ê³¼ Â±10% ì´ë‚´ (ì•ˆì •ì )
- âŒ íŒŒë¼ë¯¸í„° Â±20% ë³€í™” â†’ ì„±ê³¼ Â±50% ì´ìƒ (ë¶ˆì•ˆì • = ê³¼ì í•©)

---

### Task 1.3: Synthetic Data Permutation Test
**ë‹´ë‹¹**: í†µê³„ ë¶„ì„ê°€  
**ì˜ˆìƒ ê¸°ê°„**: 3ì¼

```python
# tests/test_overfitting_detection.py (ì‹ ê·œ)

class TestOverfittingDetection:
    """
    ê³¼ì í•© ì—¬ë¶€ í†µê³„ì  ê²€ì¦
    """
    def test_permutation_invariance(self):
        """
        ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì—ˆì„ ë•Œë„ ê°™ì€ ìˆ˜ìµì´ ë‚˜ì˜¤ëŠ”ê°€?
        â†’ YESë¼ë©´ ê³¼ì í•© (ë°ì´í„° í”¼í‚¹)
        â†’ NOë¼ë©´ ì •ìƒ (ì‹¤ì œ ì‹œê·¸ë„ ìº¡ì²˜)
        """
        
        # 1. ì›ë³¸ ë°ì´í„° ë°±í…ŒìŠ¤íŠ¸
        original_result = backtest(original_data, strategy)
        
        # 2. ë°ì´í„° ì…”í”Œ 1000íšŒ ë°˜ë³µ
        shuffled_results = []
        for i in range(1000):
            shuffled_data = original_data.copy()
            shuffled_data['close'] = np.random.permutation(shuffled_data['close'])
            result = backtest(shuffled_data, strategy)
            shuffled_results.append(result.total_return)
        
        # 3. í†µê³„ ê²€ì¦
        mean_shuffled = np.mean(shuffled_results)
        std_shuffled = np.std(shuffled_results)
        z_score = (original_result.total_return - mean_shuffled) / std_shuffled
        
        # ê¸°ëŒ€ê°’: z_score > 2.0 (5% ìœ ì˜ìˆ˜ì¤€)
        # ì˜ë¯¸: ì›ë³¸ ì„±ê³¼ê°€ ìš°ì—°ì— ë¹„í•´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜
        assert z_score > 2.0, "No statistical significance detected (likely overfitting)"
        
        print(f"Z-score: {z_score:.2f} âœ“ (í†µê³„ì ìœ¼ë¡œ ìœ ì˜)")
```

---

## ğŸ”© Phase 2: ë…¸ì´ì¦ˆ ë¹„ìœ¨ ë° ìŠ¬ë¦¬í”¼ì§€ ì•ˆì •í™” (ìš°ì„ ìˆœìœ„ 1ìˆœìœ„)

### Task 2.1: ë…¸ì´ì¦ˆ ë¹„ìœ¨ ê²½ê³„ ì¡°ê±´ ê°•í™”
**ë‹´ë‹¹**: í•µì‹¬ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ê¸°ê°„**: 2ì¼

```python
# src/utils/indicators_v2.py

import numpy as np
import pandas as pd
from typing import Tuple

def noise_ratio_stable(
    open_: pd.Series | np.ndarray,
    high: pd.Series | np.ndarray,
    low: pd.Series | np.ndarray,
    close: pd.Series | np.ndarray,
    min_range: float = 1e-8,
    outlier_percentile: float = 99.9
) -> Tuple[pd.Series, dict]:
    """
    ì•ˆì •í™”ëœ ë…¸ì´ì¦ˆ ë¹„ìœ¨ ê³„ì‚°
    
    Args:
        open_, high, low, close: OHLC ë°ì´í„°
        min_range: ìµœì†Œ high-low ë²”ìœ„ (ê·¹ì†Œê°’ ì²˜ë¦¬)
        outlier_percentile: ì´ìƒì¹˜ íŒë‹¨ ê¸°ì¤€ (99.9%)
    
    Returns:
        (noise_ratio, diagnostics)
    """
    # 1. ì…ë ¥ ê²€ì¦
    assert len(open_) == len(high) == len(low) == len(close), \
        "All inputs must have same length"
    
    # 2. High-Low ë²”ìœ„ ê³„ì‚°
    range_hl = high - low
    
    # 3. ì´ìƒì¹˜ ê°ì§€ (ë²”ìœ„ ë„ˆë¬´ í¼)
    threshold_high = np.percentile(range_hl[range_hl > 0], outlier_percentile)
    mask_extreme_range = range_hl > threshold_high
    
    # 4. ê·¹ì†Œê°’ ì²˜ë¦¬ (range ê±°ì˜ 0)
    range_hl_safe = np.maximum(range_hl, min_range)
    
    # 5. ë…¸ì´ì¦ˆ ë¹„ìœ¨ ê³„ì‚°
    noise = 1.0 - np.abs(close - open_) / range_hl_safe
    
    # 6. ë²”ìœ„ í´ë¦¬í•‘ (ì˜¤ë¥˜ ë°©ì§€)
    noise = np.clip(noise, 0.0, 1.0)
    
    # 7. ì´ìƒì¹˜ ì²˜ë¦¬ (extreme range êµ¬ê°„)
    # ì˜µì…˜ 1: Forward fill
    noise_fixed = pd.Series(noise)
    noise_fixed[mask_extreme_range] = np.nan
    noise_fixed = noise_fixed.fillna(method='ffill').fillna(0.5)
    
    # 8. NaN/Inf ìµœì¢… ì²˜ë¦¬
    noise_fixed = noise_fixed.fillna(0.5)
    noise_fixed = np.isfinite(noise_fixed).astype(float) * noise_fixed + \
                   (~np.isfinite(noise_fixed)).astype(float) * 0.5
    
    # 9. ì§„ë‹¨ ì •ë³´
    diagnostics = {
        'nan_count': np.isnan(noise).sum(),
        'outlier_count': mask_extreme_range.sum(),
        'zero_range_count': (range_hl == 0).sum(),
        'outlier_ratio': mask_extreme_range.sum() / len(range_hl),
        'mean_noise': float(np.mean(noise_fixed)),
        'std_noise': float(np.std(noise_fixed)),
    }
    
    return noise_fixed, diagnostics
```

### Task 2.2: ë™ì  ìŠ¬ë¦¬í”¼ì§€ ëª¨ë¸
**ë‹´ë‹¹**: ë¦¬ìŠ¤í¬ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ê¸°ê°„**: 3ì¼

```python
# src/backtester/slippage_model_v2.py (ì‹ ê·œ)

class DynamicSlippageModel:
    """
    ìë³¸ê·œëª¨ ë° ì‹œì¥ ìƒí™©ì— ë”°ë¥¸ ë™ì  ìŠ¬ë¦¬í”¼ì§€
    """
    
    # ê¸°ë³¸ ì„¤ì • (Upbit ê¸°ì¤€)
    CONFIG = {
        'base_slippage_bps': 5,  # 0.05% ê¸°ë³¸
        'maker_fee_bps': 2,      # 0.02% ë©”ì´ì»¤ ìˆ˜ìˆ˜ë£Œ
        'taker_fee_bps': 5,      # 0.05% í…Œì´ì»¤ ìˆ˜ìˆ˜ë£Œ
    }
    
    # ìë³¸ ê·œëª¨ë³„ ì¶”ê°€ ìŠ¬ë¦¬í”¼ì§€
    CAPITAL_TIERS = {
        'micro': {'max': 5_000_000, 'slippage_bps': 20},      # ì¶”ê°€ 0.2%
        'small': {'max': 50_000_000, 'slippage_bps': 10},     # ì¶”ê°€ 0.1%
        'medium': {'max': 500_000_000, 'slippage_bps': 5},    # ì¶”ê°€ 0.05%
        'large': {'max': float('inf'), 'slippage_bps': 0},    # ì¶”ê°€ ì—†ìŒ
    }
    
    # ì£¼ë¬¸ í¬ê¸° ë¹„ìœ¨ë³„ ìŠ¬ë¦¬í”¼ì§€
    ORDER_SIZE_MULTIPLIERS = {
        0.001: 1.0,    # 0.1% ì£¼ë¬¸ â†’ 1ë°°
        0.005: 1.5,    # 0.5% ì£¼ë¬¸ â†’ 1.5ë°°
        0.01: 2.5,     # 1% ì£¼ë¬¸ â†’ 2.5ë°°
        0.02: 4.0,     # 2% ì£¼ë¬¸ â†’ 4ë°°
    }
    
    def calculate(self,
                  order_amount: float,
                  portfolio_value: float,
                  daily_volume: float,
                  side: str = 'buy') -> float:
        """
        ë™ì  ìŠ¬ë¦¬í”¼ì§€ ê³„ì‚°
        
        Args:
            order_amount: ì£¼ë¬¸ ê¸ˆì•¡
            portfolio_value: í¬íŠ¸í´ë¦¬ì˜¤ ì´ì•¡
            daily_volume: ì¼ì¼ ê±°ë˜ëŸ‰
            side: 'buy' or 'sell'
        
        Returns:
            ìŠ¬ë¦¬í”¼ì§€ (% ë‹¨ìœ„, ì˜ˆ: 0.001 = 0.1%)
        """
        # 1. ê¸°ë³¸ ìˆ˜ìˆ˜ë£Œ
        if side == 'buy':
            base_slippage = self.CONFIG['taker_fee_bps'] / 10000
        else:
            base_slippage = self.CONFIG['taker_fee_bps'] / 10000
        
        # 2. ìë³¸ê·œëª¨ë³„ ì¶”ê°€ ìŠ¬ë¦¬í”¼ì§€
        for tier_name, tier_config in self.CAPITAL_TIERS.items():
            if portfolio_value <= tier_config['max']:
                capital_slippage = tier_config['slippage_bps'] / 10000
                break
        
        # 3. ì£¼ë¬¸ í¬ê¸° ë¹„ìœ¨ (Order Size / Daily Volume)
        order_size_ratio = order_amount / (daily_volume + 1e-10)
        
        # ì£¼ë¬¸ í¬ê¸°ë³„ ìŠ¹ìˆ˜ ê³„ì‚°
        size_multiplier = 1.0
        for ratio_threshold in sorted(self.ORDER_SIZE_MULTIPLIERS.keys()):
            if order_size_ratio <= ratio_threshold:
                size_multiplier = self.ORDER_SIZE_MULTIPLIERS[ratio_threshold]
                break
        else:
            # 2% ì´ˆê³¼ â†’ ì¶”ê°€ í˜ë„í‹°
            size_multiplier = 5.0 + (order_size_ratio - 0.02) * 10
        
        # 4. ì´ ìŠ¬ë¦¬í”¼ì§€
        total_slippage = (base_slippage + capital_slippage) * size_multiplier
        
        # 5. ë§¤ë„ ì‹œ ì¶”ê°€ (í˜¸ê°€ì°½ ë¶ˆë¦¬í•¨)
        if side == 'sell':
            total_slippage *= 1.1
        
        # 6. ìƒí•œì„  ì„¤ì • (ê·¹ë‹¨ì  ìƒí™© ë°©ì§€)
        total_slippage = min(total_slippage, 0.05)  # ìµœëŒ€ 5%
        
        return total_slippage

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
slippage_calc = DynamicSlippageModel()

# Case 1: ì†Œì•¡ ìë³¸ (1ì²œë§Œì›), ì†Œì•¡ ì£¼ë¬¸
slippage1 = slippage_calc.calculate(
    order_amount=1_000_000,
    portfolio_value=10_000_000,
    daily_volume=100_000_000
)
print(f"Micro capital, small order: {slippage1:.2%}")  # ì˜ˆìƒ: 0.3-0.5%

# Case 2: ëŒ€ì•¡ ìë³¸ (1ì–µì›), ì†Œì•¡ ì£¼ë¬¸
slippage2 = slippage_calc.calculate(
    order_amount=1_000_000,
    portfolio_value=100_000_000,
    daily_volume=100_000_000
)
print(f"Large capital, small order: {slippage2:.2%}")  # ì˜ˆìƒ: 0.1%
```

---

## ğŸ“Š Phase 3: í…ŒìŠ¤íŠ¸ ê°•í™” (ìš°ì„ ìˆœìœ„ 2ìˆœìœ„)

### Task 3.1: Edge Case í…ŒìŠ¤íŠ¸ 100ê°œ ì¶”ê°€
**ë‹´ë‹¹**: QA ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ê¸°ê°„**: 3ì¼

```python
# tests/unit/test_edge_cases_comprehensive.py (ì‹ ê·œ)

class TestEdgeCasesComprehensive:
    """
    ê·¹í•œ ìƒí™© í…ŒìŠ¤íŠ¸ (100ê°œ ì¼€ì´ìŠ¤)
    """
    
    # ê·¸ë£¹ 1: ë°ì´í„° ê·¹ê°’ (20ê°œ)
    def test_zero_range_single_row(self):
        """High == Low == Close == Open (range = 0)"""
    
    def test_zero_range_multiple_rows(self):
        """ì—°ì† 5ì¼ ê°™ì€ ê°€ê²©"""
    
    def test_extreme_gap_up(self):
        """Open << Previous Close (100ë°° ê°­)"""
    
    def test_extreme_gap_down(self):
        """Open >> Previous Close"""
    
    def test_nan_and_inf_mixed(self):
        """NaN, Inf, -Inf ì„ì¸ ë°ì´í„°"""
    
    def test_single_row_dataframe(self):
        """1í–‰ ë°ì´í„° (SMA ê³„ì‚° ë¶ˆê°€)"""
    
    def test_empty_dataframe(self):
        """ë¹ˆ ë°ì´í„°í”„ë ˆì„"""
    
    def test_all_zero_volume(self):
        """ëª¨ë“  ê±°ë˜ëŸ‰ 0"""
    
    def test_negative_prices(self):
        """ìŒìˆ˜ ê°€ê²© (ì˜¤ë¥˜ ë°ì´í„°)"""
    
    def test_price_overflow(self):
        """float64 ìµœëŒ€ê°’ì— ê°€ê¹Œìš´ ê°€ê²©"""
    
    # ... ê³„ì† 20ê°œ
    
    # ê·¸ë£¹ 2: í¬ì§€ì…˜ ê·¹ê°’ (20ê°œ)
    def test_zero_position_size(self):
        """0 í¬ê¸° í¬ì§€ì…˜"""
    
    def test_fraction_position(self):
        """0.00001ê°œ ë§¤ìˆ˜ (ê·¹ì†Œ í¬ì§€ì…˜)"""
    
    def test_million_units_position(self):
        """100ë§Œ ê°œ ë§¤ìˆ˜ (ê·¹ëŒ€ í¬ì§€ì…˜)"""
    
    # ... ê³„ì† 18ê°œ
    
    # ê·¸ë£¹ 3: ìŠ¬ë¦¬í”¼ì§€ ê·¹ê°’ (15ê°œ)
    def test_zero_daily_volume(self):
        """ì¼ì¼ ê±°ë˜ëŸ‰ 0 (division by zero)"""
    
    def test_order_size_exceeds_volume(self):
        """ì£¼ë¬¸ì•¡ > ì¼ì¼ ê±°ë˜ëŸ‰"""
    
    # ... ê³„ì† 13ê°œ
    
    # ê·¸ë£¹ 4: ì‹œê°„ ê·¹ê°’ (20ê°œ)
    def test_leap_year_feb29(self):
        """ìœ¤ë…„ 2ì›” 29ì¼"""
    
    def test_midnight_boundary(self):
        """ìì • ê¸°ì¤€ ë°ì´í„°"""
    
    # ... ê³„ì† 18ê°œ
    
    # ê·¸ë£¹ 5: í†µê³„ ê·¹ê°’ (25ê°œ)
    def test_infinite_sharpe_ratio(self):
        """ëª¨ë“  ì¼ì¼ ìˆ˜ìµì´ ìŒìˆ˜ (Sharpe = -âˆ)"""
    
    def test_division_by_zero_in_metrics(self):
        """ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²½ìš°"""
    
    # ... ê³„ì† 23ê°œ
```

### Task 3.2: ë¶€ë™ì†Œìˆ˜ì  ì •ë°€ë„ í…ŒìŠ¤íŠ¸
**ë‹´ë‹¹**: ìˆ˜ì¹˜ í•´ì„ ì „ë¬¸ê°€  
**ì˜ˆìƒ ê¸°ê°„**: 2ì¼

```python
# tests/unit/test_floating_point_precision.py (ì‹ ê·œ)

class TestFloatingPointPrecision:
    """
    ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ë¡œ ì¸í•œ ê±°ë˜ ì†ì‹¤ ë°©ì§€
    """
    
    def test_cumulative_commission_error(self):
        """
        1000íšŒ ê±°ë˜ ì‹œ ëˆ„ì  ìˆ˜ìˆ˜ë£Œ ì˜¤ì°¨ ê²€ì¦
        
        ì´ë¡ :
        1000íšŒ Ã— 0.0005 (0.05%) = 0.5
        
        ìˆ˜ì¹˜ ê³„ì‚°:
        ë°˜ë³µë¬¸ìœ¼ë¡œ 1000íšŒ ëˆ„ì í•  ì‹œ ì˜¤ì°¨ ë°œìƒ ê°€ëŠ¥
        """
        
        # ì§ì ‘ ê³„ì‚°
        direct = 1000 * 0.0005
        
        # ë°˜ë³µ ê³„ì‚°
        iterative = sum([0.0005 for _ in range(1000)])
        
        # ì˜¤ì°¨ ê²€ì¦
        assert abs(direct - iterative) < 1e-10, \
            f"Cumulative error: {abs(direct - iterative)}"
    
    def test_sma_calculation_accuracy(self):
        """
        SMA ê³„ì‚° ì‹œ ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨
        
        ì˜ˆ: [1.1, 2.2, 3.3] SMA(2)
        ìˆ˜ë™: (1.1 + 2.2) / 2 = 1.65
        pandas: ê°™ì€ ê²°ê³¼
        """
        data = pd.Series([1.1, 2.2, 3.3])
        sma_manual = (data[0] + data[1]) / 2
        sma_pandas = data.rolling(2).mean()[1]
        
        assert abs(sma_manual - sma_pandas) < 1e-14
    
    def test_portfolio_value_calculation_chain(self):
        """
        Buy â†’ Sell â†’ Buy â†’ Sell ... ë°˜ë³µ ì‹œ ëˆ„ì  ì˜¤ì°¨
        
        ê° ê±°ë˜ì—ì„œ:
        1. í¬íŠ¸í´ë¦¬ì˜¤ ê°’ = í˜„ê¸ˆ + ë³´ìœ  ìì‚° ê°€ì¹˜
        2. ì†Œìˆ˜ì  ì²˜ë¦¬ ì˜¤ë¥˜ ëˆ„ì 
        """
        
        portfolio_value = 1_000_000.0
        price = 50_000.0
        
        for i in range(100):
            # Buy
            quantity = 1.0  # 1 unit
            cost = quantity * price * 1.0005  # 0.05% ìˆ˜ìˆ˜ë£Œ
            portfolio_value -= cost
            
            # Sell
            revenue = quantity * price * 0.9995  # 0.05% ìˆ˜ìˆ˜ë£Œ
            portfolio_value += revenue
        
        # 100íšŒ ì™•ë³µ í›„ ì›ê¸ˆ íšŒë³µ í™•ì¸
        # (ê°€ê²© ë¶ˆë³€, ìˆ˜ìˆ˜ë£Œë§Œ ì†ì‹¤)
        expected_loss = 1_000_000 * 100 * 0.001  # 0.1% Ã— 100íšŒ
        expected_value = 1_000_000 - expected_loss
        
        assert abs(portfolio_value - expected_value) < 1.0, \
            f"Portfolio error too large: {abs(portfolio_value - expected_value)}"
```

---

## ğŸš€ Phase 4: ìš´ì˜ ì²´ê³„ (ìš°ì„ ìˆœìœ„ 3ìˆœìœ„)

### Task 4.1: State Machine + Circuit Breaker êµ¬í˜„
**ë‹´ë‹¹**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ê¸°ê°„**: 5ì¼

```python
# src/execution/order_state_machine_impl.py

from enum import Enum, auto
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class OrderState(Enum):
    """ì£¼ë¬¸ ìƒíƒœ ì •ì˜"""
    CREATED = auto()
    PENDING = auto()
    PARTIALLY_FILLED = auto()
    FILLED = auto()
    CANCELLED = auto()
    FAILED = auto()
    ERROR = auto()

class OrderStateMachine:
    """
    ì—„ê²©í•œ ìƒíƒœ ê´€ë¦¬ ë¨¸ì‹ 
    """
    VALID_TRANSITIONS = {
        OrderState.CREATED: {OrderState.PENDING, OrderState.FAILED},
        OrderState.PENDING: {OrderState.PARTIALLY_FILLED, OrderState.FILLED, 
                           OrderState.CANCELLED, OrderState.ERROR},
        OrderState.PARTIALLY_FILLED: {OrderState.FILLED, OrderState.CANCELLED, 
                                     OrderState.ERROR},
        OrderState.FILLED: set(),  # Terminal
        OrderState.CANCELLED: set(),  # Terminal
        OrderState.FAILED: set(),  # Terminal
        OrderState.ERROR: {OrderState.PENDING},  # Retryê°€ëŠ¥
    }
    
    def __init__(self, order_id: str, initial_state: OrderState = OrderState.CREATED):
        self.order_id = order_id
        self.state = initial_state
        self.history = [(initial_state, "initialized", datetime.now())]
        logger.info(f"Order {order_id}: {initial_state.name}")
    
    def transition(self, new_state: OrderState, reason: str = "") -> bool:
        """
        ìƒíƒœ ì „ì´ ì‹œë„
        
        Returns:
            True if successful, raises exception otherwise
        """
        if new_state not in self.VALID_TRANSITIONS.get(self.state, set()):
            msg = f"Order {self.order_id}: Invalid transition {self.state.name} â†’ {new_state.name}"
            logger.error(msg)
            raise ValueError(msg)
        
        self.state = new_state
        self.history.append((new_state, reason, datetime.now()))
        logger.info(f"Order {self.order_id}: {new_state.name} ({reason})")
        return True

# Circuit Breaker êµ¬í˜„
class CircuitBreakerState(Enum):
    CLOSED = auto()      # ì •ìƒ
    OPEN = auto()        # ì°¨ë‹¨
    HALF_OPEN = auto()   # ë³µêµ¬ ì¤‘

class CircuitBreaker:
    """
    ìë™ ì¥ì•  ì°¨ë‹¨ ì‹œìŠ¤í…œ
    """
    def __init__(self, 
                 failure_threshold: int = 5,
                 success_threshold: int = 2,
                 timeout_sec: float = 60.0):
        self.failure_threshold = failure_threshold
        self.success_threshold = success_threshold
        self.timeout_sec = timeout_sec
        
        self.state = CircuitBreakerState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None
        
        logger.info("Circuit breaker initialized")
    
    def call(self, func, *args, **kwargs):
        """
        Circuit breakerë¥¼ í†µí•œ í•¨ìˆ˜ í˜¸ì¶œ
        """
        if self.state == CircuitBreakerState.OPEN:
            elapsed = datetime.now() - self.last_failure_time
            if elapsed.total_seconds() > self.timeout_sec:
                self.state = CircuitBreakerState.HALF_OPEN
                logger.warning("Circuit breaker: Attempting recovery")
            else:
                raise CircuitBreakerOpenError(
                    f"Circuit is OPEN. Retry after {self.timeout_sec}s"
                )
        
        try:
            result = func(*args, **kwargs)
            self._on_success()
            return result
        except Exception as e:
            self._on_failure()
            raise
    
    def _on_success(self):
        """ì„±ê³µ ì²˜ë¦¬"""
        self.failure_count = 0
        
        if self.state == CircuitBreakerState.HALF_OPEN:
            self.success_count += 1
            if self.success_count >= self.success_threshold:
                self.state = CircuitBreakerState.CLOSED
                logger.info("Circuit breaker: CLOSED (recovered)")
                self.success_count = 0
    
    def _on_failure(self):
        """ì‹¤íŒ¨ ì²˜ë¦¬"""
        self.failure_count += 1
        self.last_failure_time = datetime.now()
        
        if self.failure_count >= self.failure_threshold:
            self.state = CircuitBreakerState.OPEN
            logger.error(
                f"Circuit breaker: OPEN "
                f"({self.failure_count} failures detected)"
            )
        
        if self.state == CircuitBreakerState.HALF_OPEN:
            self.state = CircuitBreakerState.OPEN
            self.success_count = 0
```

---

## ğŸ“ˆ ì™„ì„±ë„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ê³¼ì í•© ë°©ì§€ (2ì£¼)
- [ ] Task 1.1: Walk-Forward ìë™í™” ì™„ë£Œ
- [ ] Task 1.2: Parameter robustness ë¦¬í¬íŠ¸ ì™„ë£Œ
- [ ] Task 1.3: Permutation í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] í…ŒìŠ¤íŠ¸ í†µê³¼: ëª¨ë“  OOS í…ŒìŠ¤íŠ¸ PASS
- [ ] ë¬¸ì„œ ì‘ì„±: Walk-forward ê²°ê³¼ ë¦¬í¬íŠ¸
- [ ] README ìˆ˜ì •: ì‹¤ì œ OOS ìˆ˜ìµë¥  ê³µê°œ

### Phase 2: ì•ˆì •ì„± (1-2ì£¼)
- [ ] Task 2.1: ë…¸ì´ì¦ˆ ë¹„ìœ¨ ê°•í™” ì™„ë£Œ
- [ ] Task 2.2: ë™ì  ìŠ¬ë¦¬í”¼ì§€ ì™„ë£Œ
- [ ] ë°±í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰: ìƒˆ ìŠ¬ë¦¬í”¼ì§€ ëª¨ë¸ ì ìš©
- [ ] í…ŒìŠ¤íŠ¸ í†µê³¼: ëª¨ë“  ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ PASS
- [ ] ë¹„êµ ë¦¬í¬íŠ¸: "ê¸°ì¡´ vs ìƒˆ ìŠ¬ë¦¬í”¼ì§€" ê²°ê³¼

### Phase 3: ê²€ì¦ ê°•í™” (1-3ì£¼)
- [ ] Task 3.1: 100ê°œ edge case í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] Task 3.2: ë¶€ë™ì†Œìˆ˜ì  ì •ë°€ë„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: > 85%
- [ ] í…ŒìŠ¤íŠ¸ í†µê³¼: ëª¨ë“  ìƒˆ í…ŒìŠ¤íŠ¸ PASS

### Phase 4: ìš´ì˜ ê°œì„  (3-8ì£¼)
- [ ] Task 4.1: State machine + Circuit breaker êµ¬í˜„
- [ ] ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
- [ ] ì•Œë¦¼ ì‹œìŠ¤í…œ ì™„ì„±
- [ ] ë‹¤ì¤‘ ê±°ë˜ì†Œ ì§€ì› ì‹œì‘

---

**ì‘ì„± ë‚ ì§œ**: 2026ë…„ 1ì›” 7ì¼  
**ìƒíƒœ**: ğŸŸ  êµ¬í˜„ ì¤€ë¹„ ì¤‘  
**ë‹¤ìŒ ë‹¨ê³„**: Phase 1 ì‹œì‘ (Task 1.1)
